{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 뉴스 기사분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자료실에 있는 BalancedNewsCorpus_train.csv, BalancedNewsCorpus_test.csv는 국어원 뉴스 자료에서 9개 분야의 신문별 균형을 맞춘 자료로, 학습용 9,000개 시험용 1800 자료가 있는 파일이다.\n",
    "- 이 파일을 가지고 https://github.com/bentrevett/pytorch-sentiment-analysis 에 있는 pytorch sentiment analysis의 방법을 따라 한국어 뉴스기사 분류기를 만들어라\n",
    "- training data에서 evaluation data를 나누어 사용할 수 있다.(필요시)\n",
    "- 화일 이름은 MidTermProject_DS(or CL)_Group X\n",
    "- 조원 이름 명시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목표\n",
    "\n",
    "- csv 파일을 읽어서 torchtext를 사용하여 데이터를 신경망에 입력가능한 꼴로 바꾸기\n",
    "(Field, Iterator, train,test, evaluation and prediction)\n",
    "- 한국어 데이터 전처리를 위한 함수를 만들고 이를 torchtext에 통합하기 \n",
    "\n",
    "- 외부에서 학습된 한국어 단어 임베딩을 torchtext에 통합하여 사용하기 (word2vec, glove, fasttext 중 골라서 사용)\n",
    "- 제시된 여러 모델을 사용하여(transformers 제외) 성능을 향상 시키기\n",
    "- training, evaluation 한 것을 test 데이터에 적용하여 성능을 보이기.\n",
    "- predict를 사용하여 제시된 기사들의 분류 결과를 보이기\n",
    "\n",
    "- 참고 사이트\n",
    "    - https://pytorch.org/text/\n",
    "    - http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "    - https://github.com/pytorch/text\n",
    "    - https://mc.ai/using-fine-tuned-gensim-word2vec-embeddings-with-torchtext-and-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이 자료를 위해 사전학습된 임베딩\n",
    "- 필요에 따라 선택하여 사용할 수 있음\n",
    "\n",
    "### Word2vec 모델\n",
    " - 노트 : https://drive.google.com/file/d/1KOv901TPv5gepEdd4cCsJWoCHVaAV-A-/view?usp=sharing\n",
    " - Word2Vec 형태소 모델 : https://drive.google.com/file/d/1DDx6lRSTVULRFP3kslQLZsuoGZJOtoR1/view?usp=sharing\n",
    " - Word2Vec 어절 모델 : https://drive.google.com/file/d/1-RuEk-MhULduAbizgt3wjsMOCL3sM_pl/view?usp=sharing\n",
    "\n",
    "- from gensim.models.keyedvectors import KeyedVectors\n",
    "- Word2Vec_300D_space_model = KeyedVectors.load_word2vec_format(path + 'Word2Vec_300D_space.model', binary=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "### Faxttext 모델\n",
    "\n",
    "- fasttext 형태소 모델: https://drive.google.com/file/d/1-EBaAtFK7chB6qqckKmLdghR62SebEYK/view?usp=sharing\n",
    "- fasttext 어절 모델: https://drive.google.com/file/d/1-0D7Fe5oG_z9pQqOjkewtsuV_uVkh_dF/view?usp=sharing\n",
    "- fasttext 형태소 자모 모델: https://drive.google.com/file/d/1-WW_qWQZ2q3Jj9fXXex82dYHWIMHGVri/view?usp=sharing\n",
    "- fasttext 어절 자모 모델: https://drive.google.com/file/d/1-P2b8Dp09fZYO2Y__wjPNmS77PF7kfqV/view?usp=sharing\n",
    "\n",
    "\n",
    "- from gensim.models.keyedvectors import KeyedVectors\n",
    "- fasttext_model2 = KeyedVectors.load_word2vec_format(path + 'fasttext_morph_300.model', binary=False, encoding='utf-8')\n",
    "\n",
    "## Glove 모델\n",
    "\n",
    "- https://drive.google.com/drive/folders/1pzVO0jwx1Zf8p4hjf4JQn81XWzktsIdg?usp=sharing \n",
    "\n",
    "\n",
    "- from gensim.models.keyedvectors import KeyedVectors\n",
    "- Glove_model = KeyedVectors.load_word2vec_format(# 모델 경로 , binary=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "- 구현한 시스템의 성능을 정리\n"
   ]
  },
  {
   "source": [
    "## Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "embedding_path = 'word_embeddings/'\n",
    "batch_size= 128\n",
    "gpu = 'cuda:0'"
   ]
  },
  {
   "source": [
    "## Create Preprocessed data\n",
    "#### Preprocessing from https://drive.google.com/drive/folders/1pzVO0jwx1Zf8p4hjf4JQn81XWzktsIdg?usp=sharing\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_path + 'BalancedNewsCorpus_train.csv'), encoding='utf-8')\n",
    "test_df = pd.read_csv(os.path.join(data_path + 'BalancedNewsCorpus_test.csv'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import hanja\n",
    "\n",
    "def cleaning_strings(input_text):\n",
    "\n",
    "    input_text = input_text.replace('<p>',' ').replace('</p>','\\n')  # 문단 간 구분이 필요 없으므로, 문단 구분자 삭제, 줄바꿈 삽입 \n",
    "    input_text = input_text.translate(str.maketrans('①②③④⑤⑥⑦⑴⑵⑶⑷⑸ⅠⅡⅢ','123456712345123'))  # 숫자 정리\n",
    "    input_text = input_text.translate(str.maketrans('―“”‘’〉∼\\u3000', '-\"\"\\'\\'>~ '))  # 유니코드 기호 정리\n",
    "    input_text = input_text.translate({ord(i): None for i in '↑→↓⇒∇■□▲△▶▷▼◆◇○◎●★☆☞♥♪【】'})  # 특수문자 정리\n",
    "\n",
    "    # 이메일 패턴 제거\n",
    "    EMAIL_PATTERN = re.compile(r'(([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+)(\\.[a-zA-Z]{2,4}))')\n",
    "    input_text = re.sub(EMAIL_PATTERN, ' ', input_text)\n",
    "\n",
    "    # url 패턴 제거\n",
    "    URL_PATTERN = re.compile(\"(ftp|http|https)?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\")\n",
    "    input_text = re.sub(URL_PATTERN, ' ', input_text)\n",
    "    \n",
    "    input_text = re.sub('\\(.+?\\)','',input_text)  # 괄호 안 내용 삭제\n",
    "    input_text = hanja.translate(input_text, 'substitution')  # 한자 -> 한글 치환\n",
    "    input_text = re.sub('([\\'\\\",.\\(\\)\\[\\]\\{\\}<\\>\\:\\;\\/\\?\\!\\~\\…\\·\\=\\+\\-\\_])',' \\g<1> ',input_text)  # 각종 문장부호 전후 띄어쓰기\n",
    "\n",
    "\n",
    "    while True:\n",
    "        temp_text = re.sub('(.+)([.|,])([가-힣]+)','\\g<1>\\g<2> \\g<3>', input_text)  # 앞텍스트.뒷텍스트  처럼 마침표/쉼표 뒤에 띄어쓰기가 없는 경우 띄어쓰기\n",
    "        if input_text == temp_text:                         # -> 재귀적으로 구현하여 여러번 시행\n",
    "            input_text = temp_text\n",
    "            break\n",
    "        else:\n",
    "            input_text = temp_text[:]\n",
    "\n",
    "    input_text = re.sub('[0-9]+','NUM',input_text)  # 모든 숫자 NUM 으로 마스킹      \n",
    "    input_text = re.sub('[ ]{2,}',' ', input_text)  # 띄어쓰기 2번 이상 중복된 경우 하나로 통합\n",
    "\n",
    "    output_text = input_text.strip()\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_list =  \"‘, ’, ◇, ‘, ”,  ’, ', ·, \\“, ·, △, ●,  , ■, (, ), \\\", >>, `, /, -,∼,=,ㆍ<,>, .,?, !,【,】, …, ◆,%\"\n",
    "\n",
    "EMAIL_PATTERN = re.compile(r'''(([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+)(\\.[a-zA-Z]{2,4}))''', re.VERBOSE)\n",
    "URL_PATTERN = re.compile(\"(ftp|http|https)?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", re.VERBOSE)\n",
    "MULTIPLE_SPACES = re.compile(' +', re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_other(sentence: str = None) -> str:\n",
    "    \"\"\"\n",
    "    문장을 전처리 (이메일, URL, 공백 등 제거) 하는 함수\n",
    "    :param sentence: 전처리 대상 문장\n",
    "    :return: 전처리 완료된 문장\n",
    "    \"\"\"\n",
    "    sentence = re.sub(EMAIL_PATTERN, ' ', sentence)\n",
    "    sentence = re.sub(URL_PATTERN, ' ', sentence)\n",
    "    sentence = re.sub(MULTIPLE_SPACES, ' ', sentence)\n",
    "    sentence = sentence.replace(\", )\", \"\")\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_chinese(sentence: str = None) -> str:\n",
    "    \"\"\"\n",
    "    한자를 변환하는 전처리를 하는 함수\n",
    "    :param sentence: 전처리 대상 문장\n",
    "    :return: 전처리 완료된 문장\n",
    "    \"\"\"\n",
    "    # chinese character를 앞뒤로 괄호가 감싸고 있을 경우, 대부분 한글 번역임\n",
    "    sentence = re.sub(\"\\([\\u2E80-\\u2FD5\\u3190-\\u319f\\u3400-\\u4DBF\\u4E00-\\u9FCC\\uF900-\\uFAAD]+\\)\", \"\", sentence)\n",
    "    # 다른 한자가 있다면 한글로 치환\n",
    "    if re.search(\"[\\u2E80-\\u2FD5\\u3190-\\u319f\\u3400-\\u4DBF\\u4E00-\\u9FCC\\uF900-\\uFAAD]\", sentence) is not None:\n",
    "        sentence = hanja.translate(sentence, 'substitution')\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_special(sentence: str = None) -> str:\n",
    "    \"\"\"\n",
    "    특수문자를 전처리를 하는 함수\n",
    "    :param sentence: 전처리 대상 문장\n",
    "    :return: 전처리 완료된 문장\n",
    "    \"\"\"\n",
    "    sentence = re.sub(\"[.,\\'\\\"’‘”“!?]\", \"\", sentence)\n",
    "    sentence = re.sub(\"[^가-힣0-9a-zA-Z\\\\s]\", \" \", sentence)\n",
    "    sentence = re.sub(\"\\s+\", \" \", sentence)\n",
    "    \n",
    "    sentence = sentence.translate(str.maketrans(removal_list, ' '*len(removal_list)))\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_numbers(sentence: str = None) -> str:\n",
    "    \"\"\"\n",
    "    숫자를 전처리(delexicalization) 하는 함수\n",
    "    :param sentence: 전처리 대상 문장\n",
    "    :return: 전처리 완료된 문장\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = re.sub('[0-9]+', 'NUM', sentence)\n",
    "    sentence = re.sub('NUM\\s+', \"NUM\", sentence)\n",
    "    sentence = re.sub('[NUM]+', \"NUM\", sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sent(sentence: str = None) -> str:\n",
    "    \"\"\"\n",
    "    모든 전처리를 수행 하는 함수\n",
    "    :param sentence: 전처리 대상 문장\n",
    "    :return: 전처리 완료된 문장\n",
    "    \"\"\"\n",
    "    sentence = sentence.replace('<p>',' ').replace('</p>',' ')\n",
    "    sent_clean = sentence\n",
    "    sent_clean = cleansing_other(sent_clean)\n",
    "    sent_clean = cleansing_chinese(sent_clean)\n",
    "    sent_clean = cleansing_special(sent_clean)\n",
    "    sent_clean = cleansing_numbers(sent_clean)\n",
    "    sent_clean = re.sub('\\s+', ' ', sent_clean)\n",
    "\n",
    "    return sent_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing\n",
    "# train_df['News'] = train_df['News'].apply(cleaning_strings)\n",
    "# test_df['News'] = test_df['News'].apply(cleaning_strings)\n",
    "train_df['News'] = train_df['News'].apply(preprocess_sent)\n",
    "test_df['News'] = test_df['News'].apply(preprocess_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            filename      date NewsPaper  Topic  \\\n",
       "0     NLRW1900000141  20170324      부산일보    스포츠   \n",
       "1     NPRW1900000003  20110209   한국경제신문사     정치   \n",
       "2     NLRW1900000144  20100406      영남일보     사회   \n",
       "3     NLRW1900000064  20100804    광주매일신문    스포츠   \n",
       "4     NLRW1900000070  20160615    광주매일신문     문화   \n",
       "...              ...       ...       ...    ...   \n",
       "8995  NWRW1900000006  20141114     조선일보사  IT/과학   \n",
       "8996  NIRW1900000022  20101217      노컷뉴스     연예   \n",
       "8997  NLRW1900000092  20180131      국제신문     사회   \n",
       "8998  NLRW1900000103  20090206      대전일보  IT/과학   \n",
       "8999  NLRW1900000083  20090117      국제신문    스포츠   \n",
       "\n",
       "                                                   News  \n",
       "0     야구 종가 마침내 정상에 서다 야구 종가 미국이 푸에르토리코를 누르고 NUM월드베이...  \n",
       "1     외통위 NUM명중 NUM명 FTA 추가협상안만 처리 국회 외교통상통일위원회 소속 의...  \n",
       "2     한나라 지선후보 희망연대 당원 구함 공천변수 작용 주목 오늘까지 추가 모집 오는 N...  \n",
       "3     모처럼 살아난 CK포 NUM타점 합작 KIA NUMLG NUM강 진입을 놓고 혈전을...  \n",
       "4     아문화전당서 동방의 등불 만나다 일찍이 아시아의 황금 시기에 빛나던 등불의 하나였던...  \n",
       "...                                                 ...  \n",
       "8995  내가 구매한 영화 출근길의 오빠도 방에 있는 엄마도 보네 스마트폰 가족 공유 콘텐츠...  \n",
       "8996  꽃보다 예쁜 터치 선웅의 여장 이게 바로 안산 FNUM수퍼 루키 터치 TONUMCH...  \n",
       "8997  어머니 빨리 쾌차하세요 밀양참사 후 더 깊어진 고부애 같은 병실 입원해 극진히 수발...  \n",
       "8998  엑스포공원 HD 드라마 타운 성공하려면 대전 엑스포 과학공원 내 조성될 것으로 기대...  \n",
       "8999  호주오픈 테니스 NUM일 개막우승 향방 불투명 NUM시즌 테니스 첫 메이저대회인 호...  \n",
       "\n",
       "[9000 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>date</th>\n      <th>NewsPaper</th>\n      <th>Topic</th>\n      <th>News</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NLRW1900000141</td>\n      <td>20170324</td>\n      <td>부산일보</td>\n      <td>스포츠</td>\n      <td>야구 종가 마침내 정상에 서다 야구 종가 미국이 푸에르토리코를 누르고 NUM월드베이...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NPRW1900000003</td>\n      <td>20110209</td>\n      <td>한국경제신문사</td>\n      <td>정치</td>\n      <td>외통위 NUM명중 NUM명 FTA 추가협상안만 처리 국회 외교통상통일위원회 소속 의...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NLRW1900000144</td>\n      <td>20100406</td>\n      <td>영남일보</td>\n      <td>사회</td>\n      <td>한나라 지선후보 희망연대 당원 구함 공천변수 작용 주목 오늘까지 추가 모집 오는 N...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NLRW1900000064</td>\n      <td>20100804</td>\n      <td>광주매일신문</td>\n      <td>스포츠</td>\n      <td>모처럼 살아난 CK포 NUM타점 합작 KIA NUMLG NUM강 진입을 놓고 혈전을...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NLRW1900000070</td>\n      <td>20160615</td>\n      <td>광주매일신문</td>\n      <td>문화</td>\n      <td>아문화전당서 동방의 등불 만나다 일찍이 아시아의 황금 시기에 빛나던 등불의 하나였던...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8995</th>\n      <td>NWRW1900000006</td>\n      <td>20141114</td>\n      <td>조선일보사</td>\n      <td>IT/과학</td>\n      <td>내가 구매한 영화 출근길의 오빠도 방에 있는 엄마도 보네 스마트폰 가족 공유 콘텐츠...</td>\n    </tr>\n    <tr>\n      <th>8996</th>\n      <td>NIRW1900000022</td>\n      <td>20101217</td>\n      <td>노컷뉴스</td>\n      <td>연예</td>\n      <td>꽃보다 예쁜 터치 선웅의 여장 이게 바로 안산 FNUM수퍼 루키 터치 TONUMCH...</td>\n    </tr>\n    <tr>\n      <th>8997</th>\n      <td>NLRW1900000092</td>\n      <td>20180131</td>\n      <td>국제신문</td>\n      <td>사회</td>\n      <td>어머니 빨리 쾌차하세요 밀양참사 후 더 깊어진 고부애 같은 병실 입원해 극진히 수발...</td>\n    </tr>\n    <tr>\n      <th>8998</th>\n      <td>NLRW1900000103</td>\n      <td>20090206</td>\n      <td>대전일보</td>\n      <td>IT/과학</td>\n      <td>엑스포공원 HD 드라마 타운 성공하려면 대전 엑스포 과학공원 내 조성될 것으로 기대...</td>\n    </tr>\n    <tr>\n      <th>8999</th>\n      <td>NLRW1900000083</td>\n      <td>20090117</td>\n      <td>국제신문</td>\n      <td>스포츠</td>\n      <td>호주오픈 테니스 NUM일 개막우승 향방 불투명 NUM시즌 테니스 첫 메이저대회인 호...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9000 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "source": [
    "## Load torch text\n",
    "\n",
    "#### define custom dataset class\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"\n",
    "        Create a dataset from a pandas dataframe of examples and Fields\n",
    "        Arguments:\n",
    "            examples pd.DataFrame: DataFrame of examples\n",
    "            fields {str: Field}: The Fields to use in this tuple. The\n",
    "                string is a field name, and the Field is the associated field.\n",
    "            filter_pred (callable or None): use only examples for which\n",
    "                filter_pred(example) is true, or use all examples if None.\n",
    "                Default is None\n",
    "        \"\"\"\n",
    "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "        if filter_pred is not None:\n",
    "            self.examples = filter(filter_pred, self.examples)\n",
    "        self.fields = dict(fields)\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.News)\n",
    "\n",
    "class SeriesExample(Example):\n",
    "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "  \n",
    "    @classmethod\n",
    "    def fromSeries(cls, data, fields):\n",
    "        return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "        \n",
    "        for key, field in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                \"the input data\".format(key))\n",
    "            if field is not None:\n",
    "                setattr(ex, key, field.preprocess(data[key]))\n",
    "            else:\n",
    "                setattr(ex, key, data[key])\n",
    "        return ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mecab as tokenizer\n",
    "# Since all the pretrained embeddings used mecab (not sure mecab performs the best)\n",
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "\n",
    "TEXT = Field(use_vocab=True, tokenize=tokenizer.morphs, include_lengths=True)\n",
    "LABEL = Field(sequential=False, use_vocab=True, is_target=True, unk_token=None)\n",
    "fields = { 'Topic' : LABEL, 'News' : TEXT }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataFrameDataset(train_df, fields)\n",
    "test_dataset = DataFrameDataset(test_df, fields)\n",
    "TEXT.build_vocab(train_dataset, min_freq=10) \n",
    "LABEL.build_vocab(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "\n",
    "train_loader = data.BucketIterator(\n",
    "    dataset=train_dataset, batch_size=batch_size, device=gpu, sort_within_batch=True,\n",
    "    train=True, repeat=False)\n",
    "test_loader = data.BucketIterator(\n",
    "    dataset=test_dataset, batch_size=batch_size, device=gpu,\n",
    "    train=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function __main__.DataFrameDataset.sort_key(ex)>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train_loader.sort_key"
   ]
  },
  {
   "source": [
    "## Define Word Embedding\n",
    "#### Word2Vec 300D token for now\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "# Word2Vec_300D_space_model = KeyedVectors.load_word2vec_format(embedding_path + 'Word2Vec_300D_space.model', binary=False, encoding='utf-8')\n",
    "word_embeddings = KeyedVectors.load_word2vec_format(embedding_path  + 'Word2Vec_300D_token.model', binary=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19716"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "len(word_embeddings.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19704"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# add unk and pad\n",
    "embeddings = nn.Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=word_embeddings.vector_size)\n",
    "nn.init.uniform_(embeddings.weight.data)\n",
    "for i, w in enumerate(TEXT.vocab.itos):\n",
    "    if w in word_embeddings:\n",
    "        embeddings.weight.data[i] = torch.FloatTensor(word_embeddings[w])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class BiRNNMax(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_type, input_dim, hidden_dim, dropout_prob=0):\n",
    "        super().__init__()\n",
    "        self.rnn_type = rnn_type\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        if rnn_type == 'gru':\n",
    "            self.rnn = nn.GRU(\n",
    "                input_size=input_dim, hidden_size=hidden_dim,\n",
    "                bidirectional=True, dropout=dropout_prob)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=input_dim, hidden_size=hidden_dim,\n",
    "                bidirectional=True, dropout=dropout_prob)\n",
    "        else:\n",
    "            raise ValueError('Unknown RNN type!')\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.orthogonal_(self.rnn.weight_hh_l0.data)\n",
    "        init.kaiming_normal_(self.rnn.weight_ih_l0.data)\n",
    "        init.constant_(self.rnn.bias_hh_l0.data, val=0)\n",
    "        init.constant_(self.rnn.bias_ih_l0.data, val=0)\n",
    "        init.orthogonal_(self.rnn.weight_hh_l0_reverse.data)\n",
    "        init.kaiming_normal_(self.rnn.weight_ih_l0_reverse.data)\n",
    "        init.constant_(self.rnn.bias_hh_l0_reverse.data, val=0)\n",
    "        init.constant_(self.rnn.bias_ih_l0_reverse.data, val=0)\n",
    "        if self.rnn_type == 'lstm':\n",
    "            # Set the initial forget bias values to 1\n",
    "            self.rnn.bias_ih_l0.data.chunk(4)[1].fill_(1)\n",
    "            self.rnn.bias_ih_l0_reverse.data.chunk(4)[1].fill_(1)\n",
    "\n",
    "    def forward(self, inputs, length):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (Variable): A float variable of size\n",
    "                (max_length, batch_size, input_dim).\n",
    "            length (Tensor): A long tensor of sequence lengths.\n",
    "\n",
    "        Returns:\n",
    "            output (Variable): An encoded sequence vector of size\n",
    "                (batch_size, hidden_dim).\n",
    "        \"\"\"\n",
    "\n",
    "        inputs_packed = pack_padded_sequence(inputs, lengths=list(length))\n",
    "        rnn_outputs_packed, _ = self.rnn(inputs_packed)\n",
    "        rnn_outputs, _ = pad_packed_sequence(rnn_outputs_packed)\n",
    "        # To avoid the weired bug when taking the max of a length-1 sentence.\n",
    "        output = rnn_outputs.max(dim=0, keepdim=True)[0].squeeze(0)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNNTextClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_type, num_classes, word_dim, hidden_dim,\n",
    "                 clf_dim, dropout_prob=0):\n",
    "        super().__init__()\n",
    "        self.rnn_type = rnn_type\n",
    "        self.num_classes = num_classes\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.clf_dim = clf_dim\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.birnn_max = BiRNNMax(\n",
    "            rnn_type=rnn_type, input_dim=word_dim, hidden_dim=hidden_dim,\n",
    "            dropout_prob=dropout_prob)\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(in_features=2 * hidden_dim, out_features=clf_dim),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(in_features=clf_dim, out_features=num_classes))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.birnn_max.reset_parameters()\n",
    "        init.kaiming_normal_(self.clf[0].weight.data)\n",
    "        init.constant_(self.clf[0].bias.data, val=0)\n",
    "        init.uniform_(self.clf[3].weight.data, -0.005, 0.005)\n",
    "        init.constant_(self.clf[3].bias.data, val=0)\n",
    "\n",
    "    def forward(self, inputs, length, batch_first=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (Variable):\n",
    "                If use_pretrained_embeddings is False, this is a long\n",
    "                    variable of size (max_length, batch_size) or\n",
    "                    (batch_size, max_length) (if batch_first) which\n",
    "                    contains indices of words.\n",
    "                If use_pretrained_embeddings is True, this is a 3D\n",
    "                    variable of size (max_length, batch_size, word_dim)\n",
    "                    or (batch_size, max_length, word_dim).\n",
    "            length (Tensor): A long tensor of lengths.\n",
    "            batch_first (bool): If True, sequences in a batch are\n",
    "                aligned along the first dimension of inputs.\n",
    "\n",
    "        Returns:\n",
    "            logit (Variable): A variable containing unnormalized log\n",
    "                probability for each class.\n",
    "        \"\"\"\n",
    "\n",
    "        if batch_first:\n",
    "            inputs = inputs.transpose(0, 1)\n",
    "        inputs = self.dropout(inputs)\n",
    "        sentence_vector = self.birnn_max(inputs=inputs, length=length)\n",
    "        sentence_vector = self.dropout(sentence_vector)\n",
    "        logit = self.clf(sentence_vector)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "model = BiRNNTextClassifier(\n",
    "        rnn_type='lstm', num_classes=len(LABEL.vocab), word_dim=300,\n",
    "        hidden_dim=300, clf_dim=300,\n",
    "        dropout_prob=0.0)\n",
    "optimizer = optim.Adam(list(model.parameters()))\n",
    "loss_weight = None\n",
    "criterion = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "embeddings.cuda(gpu)\n",
    "model.cuda(gpu)\n",
    "criterion.cuda(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "* Epoch 0 finished\n",
      "  - Valid Loss = 1.3191\n",
      "  - Valid Accuracy = 0.4995\n",
      "* Epoch 1 finished\n",
      "  - Valid Loss = 1.2649\n",
      "  - Valid Accuracy = 0.4995\n",
      "* Epoch 2 finished\n",
      "  - Valid Loss = 1.2061\n",
      "  - Valid Accuracy = 0.5271\n",
      "* Epoch 3 finished\n",
      "  - Valid Loss = 1.2115\n",
      "  - Valid Accuracy = 0.5495\n",
      "* Epoch 4 finished\n",
      "  - Valid Loss = 1.1540\n",
      "  - Valid Accuracy = 0.5641\n",
      "* Epoch 5 finished\n",
      "  - Valid Loss = 1.2072\n",
      "  - Valid Accuracy = 0.5000\n",
      "* Epoch 6 finished\n",
      "  - Valid Loss = 1.0308\n",
      "  - Valid Accuracy = 0.5625\n",
      "* Epoch 7 finished\n",
      "  - Valid Loss = 1.0510\n",
      "  - Valid Accuracy = 0.6089\n",
      "* Epoch 8 finished\n",
      "  - Valid Loss = 0.9245\n",
      "  - Valid Accuracy = 0.6792\n",
      "* Epoch 9 finished\n",
      "  - Valid Loss = 0.9672\n",
      "  - Valid Accuracy = 0.6495\n",
      "* Epoch 10 finished\n",
      "  - Valid Loss = 0.8658\n",
      "  - Valid Accuracy = 0.7016\n",
      "* Epoch 11 finished\n",
      "  - Valid Loss = 0.7278\n",
      "  - Valid Accuracy = 0.7635\n",
      "* Epoch 12 finished\n",
      "  - Valid Loss = 0.7680\n",
      "  - Valid Accuracy = 0.7250\n",
      "* Epoch 13 finished\n",
      "  - Valid Loss = 0.6861\n",
      "  - Valid Accuracy = 0.7656\n",
      "* Epoch 14 finished\n",
      "  - Valid Loss = 0.7237\n",
      "  - Valid Accuracy = 0.7469\n",
      "* Epoch 15 finished\n",
      "  - Valid Loss = 0.7051\n",
      "  - Valid Accuracy = 0.7724\n",
      "* Epoch 16 finished\n",
      "  - Valid Loss = 0.7286\n",
      "  - Valid Accuracy = 0.7583\n",
      "* Epoch 17 finished\n",
      "  - Valid Loss = 0.6591\n",
      "  - Valid Accuracy = 0.7786\n",
      "* Epoch 18 finished\n",
      "  - Valid Loss = 0.6587\n",
      "  - Valid Accuracy = 0.7839\n",
      "* Epoch 19 finished\n",
      "  - Valid Loss = 0.6256\n",
      "  - Valid Accuracy = 0.7979\n",
      "* Epoch 20 finished\n",
      "  - Valid Loss = 0.6105\n",
      "  - Valid Accuracy = 0.8010\n",
      "* Epoch 21 finished\n",
      "  - Valid Loss = 0.6440\n",
      "  - Valid Accuracy = 0.8010\n",
      "* Epoch 22 finished\n",
      "  - Valid Loss = 0.6267\n",
      "  - Valid Accuracy = 0.7927\n",
      "* Epoch 23 finished\n",
      "  - Valid Loss = 0.6402\n",
      "  - Valid Accuracy = 0.8000\n",
      "* Epoch 24 finished\n",
      "  - Valid Loss = 0.6328\n",
      "  - Valid Accuracy = 0.8057\n",
      "* Epoch 25 finished\n",
      "  - Valid Loss = 0.7058\n",
      "  - Valid Accuracy = 0.7922\n",
      "* Epoch 26 finished\n",
      "  - Valid Loss = 0.7530\n",
      "  - Valid Accuracy = 0.7771\n",
      "* Epoch 27 finished\n",
      "  - Valid Loss = 0.7175\n",
      "  - Valid Accuracy = 0.7833\n",
      "* Epoch 28 finished\n",
      "  - Valid Loss = 0.6547\n",
      "  - Valid Accuracy = 0.8073\n",
      "* Epoch 29 finished\n",
      "  - Valid Loss = 0.7378\n",
      "  - Valid Accuracy = 0.7927\n",
      "* Epoch 30 finished\n",
      "  - Valid Loss = 0.6807\n",
      "  - Valid Accuracy = 0.7990\n",
      "* Epoch 31 finished\n",
      "  - Valid Loss = 0.7316\n",
      "  - Valid Accuracy = 0.8026\n",
      "* Epoch 32 finished\n",
      "  - Valid Loss = 0.7825\n",
      "  - Valid Accuracy = 0.7964\n",
      "* Epoch 33 finished\n",
      "  - Valid Loss = 0.7631\n",
      "  - Valid Accuracy = 0.7979\n",
      "* Epoch 34 finished\n",
      "  - Valid Loss = 0.8267\n",
      "  - Valid Accuracy = 0.7906\n",
      "* Epoch 35 finished\n",
      "  - Valid Loss = 0.8900\n",
      "  - Valid Accuracy = 0.7932\n",
      "* Epoch 36 finished\n",
      "  - Valid Loss = 0.8565\n",
      "  - Valid Accuracy = 0.7979\n",
      "* Epoch 37 finished\n",
      "  - Valid Loss = 0.8539\n",
      "  - Valid Accuracy = 0.7943\n",
      "* Epoch 38 finished\n",
      "  - Valid Loss = 0.9464\n",
      "  - Valid Accuracy = 0.7937\n",
      "* Epoch 39 finished\n",
      "  - Valid Loss = 0.9226\n",
      "  - Valid Accuracy = 0.8042\n",
      "* Epoch 40 finished\n",
      "  - Valid Loss = 0.9668\n",
      "  - Valid Accuracy = 0.7990\n",
      "* Epoch 41 finished\n",
      "  - Valid Loss = 1.0388\n",
      "  - Valid Accuracy = 0.7953\n",
      "* Epoch 42 finished\n",
      "  - Valid Loss = 0.8970\n",
      "  - Valid Accuracy = 0.8010\n",
      "* Epoch 43 finished\n",
      "  - Valid Loss = 0.9345\n",
      "  - Valid Accuracy = 0.7974\n",
      "* Epoch 44 finished\n",
      "  - Valid Loss = 0.8805\n",
      "  - Valid Accuracy = 0.8036\n",
      "* Epoch 45 finished\n",
      "  - Valid Loss = 0.9977\n",
      "  - Valid Accuracy = 0.7896\n",
      "* Epoch 46 finished\n",
      "  - Valid Loss = 0.9642\n",
      "  - Valid Accuracy = 0.8021\n",
      "* Epoch 47 finished\n",
      "  - Valid Loss = 0.9950\n",
      "  - Valid Accuracy = 0.8021\n",
      "* Epoch 48 finished\n",
      "  - Valid Loss = 1.0310\n",
      "  - Valid Accuracy = 0.8021\n",
      "* Epoch 49 finished\n",
      "  - Valid Loss = 1.0492\n",
      "  - Valid Accuracy = 0.8042\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "def run_iter(batch):\n",
    "    inputs, length = batch.News\n",
    "    inputs = embeddings(inputs)\n",
    "    logit = model(inputs=inputs, length=list(length))\n",
    "\n",
    "    label = batch.Topic\n",
    "    loss = criterion(input=logit, target=label)\n",
    "    accuracy = torch.eq(logit.max(1)[1], label).float().mean()\n",
    "    if model.training:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "        optimizer.step()\n",
    "    return loss.data.item(), accuracy.data.item()\n",
    "\n",
    "def validate():\n",
    "    loss_sum = accuracy_sum = 0\n",
    "    num_batches = len(test_loader)\n",
    "    model.eval()\n",
    "    for valid_batch in test_loader:\n",
    "        loss, accuracy = run_iter(valid_batch)\n",
    "        loss_sum += loss\n",
    "        accuracy_sum += accuracy\n",
    "    return loss_sum / num_batches, accuracy_sum / num_batches\n",
    "\n",
    "iter_count = 0\n",
    "best_valid_accuracy = -1\n",
    "for cur_epoch in range(50):\n",
    "    for train_batch in train_loader:\n",
    "        if not model.training:\n",
    "            model.train()\n",
    "        train_loss, train_accuracy = run_iter(train_batch)\n",
    "        iter_count += 1\n",
    "\n",
    "    print(f'* Epoch {cur_epoch} finished')\n",
    "    valid_loss, valid_accuracy = validate()\n",
    "    print(f'  - Valid Loss = {valid_loss:.4f}')\n",
    "    print(f'  - Valid Accuracy = {valid_accuracy:.4f}')\n",
    "    # if valid_accuracy > best_valid_accuracy:\n",
    "    #     best_valid_accuracy = valid_accuracy\n",
    "    #     model_filename = (f'model-{cur_epoch}-{valid_accuracy:.4f}.pt')\n",
    "    #     model_path = os.path.join(args.save_dir, model_filename)\n",
    "    #     state_dict = 'model':  model.state_dict()\n",
    "    #     torch.save(state_dict, model_path)\n",
    "    #     torch.save(state_dict, os.path.join(args.save_dir,'final.pt'))\n",
    "    #     print(f'  - Saved the new best model to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n",
    "\n",
    "####  뉴스 labels\n",
    "    -  IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-25-45277e230217>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-45277e230217>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def predict_news(model, sentence, min_len=5):\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def predict_news(model, sentence, min_len=5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'predict_news' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-458249891701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"발이 아프면 걷는 자세가 나빠지고 자연스럽게 무릎, 골반, 허리에 이상이 생길 수 있다. 이를 예방하려면 평소 발바닥 근육을 스트레칭하고 강화하는 운동을 지속하는 게 중요하다.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"전기차 화재 사고가 연이어 발생하는 가운데 불타지 않는 SK이노베이션 배터리가 주목받는다. SK이노베이션의 배터리는 글로벌 배터리 업체 중 유일하게 단 한건의 화재도 일어나지 않았다. 이같은 비결이 자동차 안정성을 결정짓는 분리막 내재화에 있다는 평가가 나온다.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpredict_news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_news' is not defined"
     ]
    }
   ],
   "source": [
    "## 아래 문장의 정답은 5-8-1-2-4-6-7-3-0\n",
    "## 연예/문화, 정치/경제/사회/생활 등 명확히 구별되기 어려운 범주들이 있음...\n",
    "\n",
    "sentence = \"차진 식감과 부드러운 감촉을 모두 지닌 식빵, 결결이 찢어지는 크루아상, 둥글고 크게 구운 호밀빵 모두 모양새부터 알차고 단단했다. 디저트로 눈을 옮기면 국가 대표팀같이 뭐 하나 빼놓을 수 없는 케이크가 나란히 줄을 서 있었다.\"\n",
    "sentence =\"정부는 2012년 예산의 공고안과 배정계획을 1월3일 국무회의에서 의결하고 연초부터 바로 집행에 들어간다. 세계 경제의 불확실성이 높아지고 경기가 둔화할 가능성이 높은 만큼 조기 집행에 박차를 가할 예정이다\"\n",
    "sentence = \"국세청은 특히 서민생활에 피해를 주면서 폭리를 취하는 매점매석 농수산물 유통업체 등에 대한 추적조사를 강화하고, 지방청에 ‘민생침해 사업자 조사전담팀’을 꾸려 민생침해 탈세자에 대한 엄정 대응에 나설 계획이라고 밝혔다\"\n",
    "sentence = \"26일 제25회 부산국제영화제 갈라 프레젠테이션 부문 초청작 '스파이의 아내' 온라인 기자회견이 진행됐다. 작품을 연출한 구로사와 감독이 참석해 작품에 대한 이야기를 나눴다.\"\n",
    "sentence = \"70대 운전사가 몰던 25인승 어린이 통학버스가 주유소로 돌진해 차량 3대를 들이 받았다. 다행히 통학버스에 운전자 외에는 탑승자가 없어 큰 인명피해는 피했다. 운전자는 차량 결함을 주장하고 있으나, 경찰은 운전자 과실 여부도 조사 중이다.\"\n",
    "sentence = \"토트넘이 손흥민에게 주급 20만 파운드(약 3억원)-5년 재계약을 제안할 준비를 마쳤다.' 25일(한국시각) 영국 대중일간 더선의 헤드라인이다. 조제 무리뉴 토트넘 감독이 번리전을 앞두고 기자회견을 통해 구단에 토트넘에서의 손흥민의 장밋빛 미래를 확신하며 재계약을 요청한 직후 영국 현지 언론에선 손흥민 재계약 보도가 쏟아지고 있다.\"\n",
    "sentence = \"공연은 말 그대로 다채로움 그 자체였다. 발레극인지, 현대무용극인지, 전통극인지, 연극인지, 연극이면 다인극인지 1인극인지 모를 정도로 다양한 장르의 결합이 먼저 눈에 띈다.\"\n",
    "sentence = \"발이 아프면 걷는 자세가 나빠지고 자연스럽게 무릎, 골반, 허리에 이상이 생길 수 있다. 이를 예방하려면 평소 발바닥 근육을 스트레칭하고 강화하는 운동을 지속하는 게 중요하다.\"\n",
    "sentence = \"전기차 화재 사고가 연이어 발생하는 가운데 불타지 않는 SK이노베이션 배터리가 주목받는다. SK이노베이션의 배터리는 글로벌 배터리 업체 중 유일하게 단 한건의 화재도 일어나지 않았다. 이같은 비결이 자동차 안정성을 결정짓는 분리막 내재화에 있다는 평가가 나온다.\"\n",
    "predict_news(model, sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('2020_nlp': conda)",
   "language": "python",
   "name": "python37964bit2020nlpconda0bb027a603974b76a9f3e8872e694816"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}